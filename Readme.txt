ðŸ“Œ Loan Prediction Project (Kaggle Case Study)

Objective:
Predict whether a loan should be approved (Y) or not (N) using applicant data.

Steps Taken:

EDA â€“ Visualized categorical and numerical features, checked correlations.

Preprocessing â€“ Handled missing values, one-hot encoding, feature alignment.

Models Tried â€“ Logistic Regression, Random Forest, XGBoost.

Tuning â€“ Hyperparameter tuning with GridSearchCV, threshold tuning.

Business Validation â€“ Evaluated trade-offs between approvals and risk.

Key Results:

Logistic Regression: ~85% accuracy (good baseline).

Random Forest: balanced performance (~84%).

Tuned XGBoost: 82% accuracy @ threshold 0.5.

XGBoost with threshold 0.4 â†’ Recall â†‘ (97%), more approvals but riskier.

XGBoost with threshold 0.6 â†’ Precision â†‘ (fewer risky approvals), fewer loans approved.

ðŸ“Š Business Validation

Banks value risk minimization more than just approvals.

Threshold = 0.4:

High recall (97%) â†’ Approves almost all good loans, but lets in more risky loans.

Threshold = 0.6:

Higher precision â†’ Fewer false approvals (bad loans), safer for the bank.

Decision:
ðŸ‘‰ Recommend threshold = 0.6 for business use (prioritizes minimizing defaults).
ðŸ‘‰ Threshold = 0.4 can be used if the bank wants aggressive lending (higher approvals).